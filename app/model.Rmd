---
title: "model"
author: "Ang Sonam Sherpa"
date: "12/14/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(rstanarm)
library(tidymodels)
```


```{r}

# I am creating a OLS model with the candidate data set. The candidate data set
# has more data points since it includes value for each individual candidate
# and their gender.

# Whereas, the aggregate data set only includes the proportion of women in a
# district, which means it only has 68 data points which can make the reading
# less reliable.

# creating a function to test different models for the candidate data set and
# its individual candidates gender

# model for individual candidates' gender instead of aggregates

# converting gender to 1 (female) and 0 (male) to conduct a numerical regression

cand2013 <- cand2013 %>%
    mutate(gender = case_when(
        gender == "female" ~ 1,
        TRUE ~ 0
    ))


set.seed(10)

cand2013_split <- initial_split(cand2013, prob = 0.8)
cand2013_train <- training(cand2013_split)
cand2013_test <- testing(cand2013_split)

estimate_error <- function(test_recipe){
    
    # creating the model with linear regression  
    
    cand2013_model <-
        linear_reg() %>%
        set_engine("lm")
    
    # creating work flow by adding model and recipe
    
    cand2013_workflow <- workflow() %>%
        add_model(cand2013_model) %>%
        add_recipe(test_recipe)
    
    # I used the train set to fit the model and the test set to predict, after
    # which I used bind_cols to add in the actual data and the predicted data
    # into a single tibble.
    
    prediction_results <- cand2013_workflow %>%
        fit(data = cand2013_train) %>%
        predict(new_data = cand2013_test) %>%
        bind_cols(cand2013_test %>% select(gender))
    
    # I used the metrics function to calculate the errors. I decided to use rsq and
    # rmse for testing the accuracy of the models, simply because I thought they
    # were sufficient for this purpose.
    
    prediction_results %>%
        metrics(truth = gender, estimate = .pred)
}

```



```{r}

# To figure out the intercepts of each explanatory variable and include the
# non-zero intercept variables in a new model

set.seed(10)

model1 <- stan_glm(gender ~ winner2008 + income2001 + professionaljobs2001 +
                       adminjobs2001 + pop2011 + povline2011 + popdens2011 +
                       hdi2011 + literacy2011 + femalepop2011 +
                       femaleliteracy2011 + grade_10 + development_region +
                       geographical_region + age - 1,
                   refresh = 0,
                   data = cand2013)

print(model1, digits = 3)

# creating the model with non-zero coefficient variables

set.seed(10)

model2 <- stan_glm(gender ~ winner2008 + hdi2011 + development_region - 1,
                   refresh = 0,
                   data = cand2013)

print(model2, 3)

```


```{r}

# Testing various recipes and their error value. I firstly put in ever
# explanatory variable I had. After seeing the intercepts of the variables
# in stan glm, I then calculated error values for three models - one with no
# with all the variables, one with zero-coefficient ones and one with non-zero
# coefficient variables

# all variables

recipe1 <- 
    recipe(gender ~ winner2008 + income2001 + professionaljobs2001 +
                       adminjobs2001 + pop2011 + povline2011 + popdens2011 +
                       hdi2011 + literacy2011 + femalepop2011 +
                       femaleliteracy2011 + grade_10 + development_region +
                       geographical_region + age,
           data = cand2013_train)

error1 <- estimate_error(recipe1)

# non zero coefficient variables

recipe2 <- recipe(gender ~ winner2008 + hdi2011 + development_region,
                 data = cand2013_train)

error2 <- estimate_error(recipe2)

# zero coefficient variables

recipe3 <- recipe(gender ~ professionaljobs2001 + adminjobs2001 + pop2011 + 
                     povline2011 + popdens2011 + literacy2011 + femalepop2011 +
                     femaleliteracy2011 + geographical_region + age,
                 data = cand2013_train)

error3 <- estimate_error(recipe3)

# finally putting all the error values in the same tibble

error <- tibble(Metric = c("RMSE", "RSQ", "MAE"),
                "All Variables" = error1$.estimate,
                "Non-zero Variables" = error2$.estimate,
                "Zero variables" = error3$.estimate)

```


```{r}

# saving the model and error in a separate file to save time while loading

write.csv(error, "error")
saveRDS(model2, "model2")

```

